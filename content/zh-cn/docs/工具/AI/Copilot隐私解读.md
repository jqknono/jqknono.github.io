---
title: Copilot隐私解读
---

考虑公司机密信息是否存在泄露的可能, Github有以下声明.

|  |  |  |
| --- |  --- |  --- |
| What data does Copilot for Individuals collect? | GitHub Copilot relies on file content and additional data to work. It collects data to provide the service, some of which is then retained for further analysis and product improvements. GitHub Copilot collects the following data for individual users:#### User Engagement DataWhen you use GitHub Copilot it will collect usage information about events generated when interacting with the IDE or editor. These events include user edit actions like completions accepted and dismissed, and error and general usage data to identify metrics like latency and features engagement. This information may include personal data, such as pseudonymous identifiers.#### Code Snippets DataDepending on your preferred telemetry settings, GitHub Copilot may also collect and retain the following, collectively referred to as "code snippets": source code that you are editing, related files and other files open in the same IDE or editor, URLs of repositories and files path. | GitHub Copilot依赖文件内容和附加数据进行工作。它收集数据以提供服务，其中一些数据会被保留进行进一步的分析和产品改进。GitHub Copilot为个人用户收集以下数据：**用户参与数据**当您使用GitHub Copilot时，它将收集与IDE或编辑器交互时生成的使用信息。这些事件包括用户编辑操作，如接受和拒绝补全，以及错误和一般使用数据，以识别诸如延迟和特性参与率等指标。该信息可能包括个人数据，如匿名标识符。**代码片段数据**根据您的首选遥测设置，GitHub Copilot还可能收集并保留以下内容，统称为"代码片段"：您正在编辑的源代码、相关文件以及在同一IDE或编辑器中打开的其他文件、仓库的URL以及文件路径。 |
| How is the data in Copilot for Individuals used and shared? | User Engagement Data and Code Snippets Data is used by GitHub, Microsoft, and OpenAI to improve GitHub Copilot and related services and to conduct product and academic research about developers.Such uses may include:-   Directly improving GitHub Copilot, including assessing different strategies in processing and predicting which suggestions users may find helpful-   Developing and improving closely related developer products and services from GitHub, Microsoft, and OpenAI-   Investigating and detecting potential abuse of GitHub Copilot or violation of [Acceptable Use Policies](https://docs.github.com/en/site-policy/acceptable-use-policies/github-acceptable-use-policies)-   Conducting experiments and research related to developers and their use of developer tools and services-   Evaluating GitHub Copilot, e.g., by measuring the positive impact it has on the user-   Improving the underlying code generation models, e.g., by providing positive and negative examples-   Fine tuning ranking and sorting algorithms and prompt craftingWhen processing Code Snippets Data, GitHub takes the protection measures described below in [How is the transmitted Code Snippets data protected?](https://github.com/features/copilot#how-is-the-transmitted-code-snippets-data-protected) and follows responsible practices in accordance with our [Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement) so that the use of your telemetry data to improve these models does not result in this data being shared with other GitHub Copilot users. | GitHub、Microsoft和OpenAI使用用户参与数据和代码片段数据来改进GitHub Copilot及相关服务，并对开发人员进行产品和学术研究。这些用途可能包括：-   直接改进GitHub Copilot，包括评估不同的处理和预测策略，以确定哪些建议对用户有帮助-   开发和改进与GitHub、Microsoft和OpenAI密切相关的开发人员产品和服务-   调查和检测潜在的GitHub Copilot滥用或违反可接受使用政策的行为-   进行与开发人员及其使用开发人员工具和服务相关的实验和研究-   评估GitHub Copilot，例如通过衡量它对用户的积极影响-   改进底层代码生成模型，例如提供正面和负面案例-   调整排名和排序算法以及提示的构造在处理代码片段数据时，GitHub采取下面描述的保护措施以保护传输的代码片段数据, [How is the transmitted Code Snippets data protected?](https://github.com/features/copilot#how-is-the-transmitted-code-snippets-data-protected) ，并遵循我们的隐私声明[Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement)中规定的负责任的实践，确保使用您的遥测数据来改进这些模型不会导致这些数据与其他GitHub Copilot用户共享。 |
| How is the transmitted Code Snippets data protected? | We know that user edit actions, source code snippets, and URLs of repositories and file paths are sensitive data. Consequently, several measures of protection are applied, including:-   The transmitted data is encrypted in transit and at rest-   Access is strictly controlled. The data can only be accessed by (1) named GitHub personnel working on the GitHub Copilot team or on the GitHub platform health team, (2) Microsoft personnel working on or with the GitHub Copilot team, and (3) OpenAI personnel who work on GitHub Copilot-   Role-based access controls and multi-factor authentication are required for personnel accessing code snippet data | 我们知道用户编辑操作、源代码片段和仓库的URL和文件路径是敏感数据。因此，采取了几项保护措施，包括：-   传输的数据在传输和静态状态下均进行加密-   访问权限受到严格控制。该数据仅可被以下人员访问：(1)在GitHub Copilot团队或GitHub平台健康团队工作的具名GitHub人员，(2)在GitHub Copilot团队工作或与其合作的Microsoft人员，(3)在GitHub Copilot工作的OpenAI人员-   要求访问代码片段数据的人员使用基于角色的访问控制和多因素身份验证。 |
| How can users of Copilot for Individuals control use of their Code Snippets Data? | GitHub Copilot gives you choices about how it uses the data it collects.User Engagement Data (which includes pseudonymous identifiers and general usage data), is required for the use of GitHub Copilot and will continue to be collected, processed, and shared with Microsoft and OpenAI as you use GitHub Copilot.Users of Copilot for Individuals can choose whether Code Snippets Data is retained by GitHub and further processed and shared with Microsoft and OpenAI by [adjusting user settings](https://github.com/settings/copilot).Users of Copilot for Individuals can request deletion of Code Snippet Data associated with their GitHub identity. GitHub Copilot is powered by Codex, which is a learning model trained by OpenAI. To request removal of your code from Codex's training data, please follow the procedure outlined in the "Copyright Complaints" section in OpenAI's [terms of use](https://openai.com/terms/). For more information, please contact us by [filling out a support ticket](https://support.github.com/request). | GitHub Copilot为您提供了如何使用所收集数据的选择。对于使用GitHub Copilot所必需的用户参与数据（包括匿名标识符和通用使用数据），将继续在您使用GitHub Copilot时进行收集、处理和与Microsoft和OpenAI共享。**对于个人用户的Copilot，用户可通过调整用户设置[adjusting user settings](https://github.com/settings/copilot)来选择是否保留代码片段数据，并进一步处理和与Microsoft和OpenAI共享。**个人用户的Copilot可以请求删除与其GitHub身份相关联的代码片段数据。GitHub Copilot由OpenAI训练的学习模型Codex驱动。若要请求从Codex的训练数据中删除您的代码，请按照OpenAI使用条款 [terms of use](https://openai.com/terms/) 中"版权投诉"部分中概述的程序。如果需要更多信息，请通过填写支持工单与我们联系 [filling out a support ticket](https://support.github.com/request)。 |
| **Will my private code be shared with other users?** | No. We follow responsible practices in accordance with our [Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement) to ensure that your code snippets will not be used as suggested code for other users of GitHub Copilot. | **不会这样做。我们按照我们的隐私声明 [Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/github-privacy-statement) 采取负责任的做法，确保您的代码片段不会被用作GitHub Copilot的其他用户所建议的代码。** |
| Does GitHub Copilot ever output personal data? | Because Codex, the model powering GitHub Copilot, was trained on publicly available code, its training set included public personal data that was included in that code. From our internal testing, we found it to be very rare that GitHub Copilot suggestions included personal data verbatim from the training set. In some cases, the model will suggest what appears to be personal data -- email addresses, phone numbers, etc. -- but those suggestions are actually fictitious information synthesized from patterns in training data and therefore do not relate to any particular individual. For example, when one of our engineers prompted GitHub Copilot with, "My name is Mona and my birthdate is," GitHub Copilot suggested a random, fictitious date of "December 12," which is not Mona's actual birthdate. We have also implemented a filter that blocks emails when shown in standard formats, but it's still possible to get the model to suggest this sort of content if you try hard enough. We will keep improving the filter system to be more intelligent to detect and remove more personal data from the GitHub Copilot suggestions. | 因为支持GitHub Copilot的模型Codex是通过公开可用代码进行训练的，所以它的训练集包含了相关代码中所含的公开个人数据。根据我们内部测试的结果，GitHub Copilot的建议极少会直接使用训练集中的个人数据。在某些情况下，模型会建议看起来是个人数据------电子邮件地址、电话号码等，但这些建议实际上是从训练数据中的模式合成的虚构信息，因此与任何特定个人无关。例如，当我们的一位工程师使用"我的名字是莫娜，我的生日是"来启动GitHub Copilot时，GitHub Copilot建议一个随机的、虚构的"12月12日"作为生日，而不是莫娜的实际生日。我们还实现了过滤器，用于阻止以标准格式显示的电子邮件，但如果您足够努力，仍有可能让模型建议此类内容。我们将继续改进过滤器系统，使其更加智能化，以便从GitHub Copilot的建议中检测和删除更多的个人数据。 |

For more information on how GitHub processes and uses personal data, please see the [GitHub Copilot Privacy Statement](https://docs.github.com/en/site-policy/privacy-policies/).

Copilot已明确声明数据采集范围及用途, 允许停止代码保留, 并且私有代码不会成为建议结果.

Copilot有它的声明, 我们可以选择不信任它, 只是选择信任或者不信任都有其代价.

我倾向于信任其隐私声明, 因为最大的风险是泄露代码片段, 除非Github刻意针对盗取, 否则没有人能从熵增的海洋里恢复原来一瓶水的样子, 而开发者的效率的提升足够整明其对个人和公司都是利大于弊的.